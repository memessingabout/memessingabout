# scrape_uber_trips.py
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager  # Works for Brave too
import json
import time
import pandas as pd
import polyline
from datetime import datetime, timedelta

# === CONFIG ===
EMAIL = "your_uber_email@example.com"  # Edit this
PASSWORD = "your_uber_password"        # Edit this (keep secure!)
OUTPUT = "uber_trips_full.csv"

# Set up Brave options
opts = Options()
opts.binary_location = "/Applications/Brave Browser.app/Contents/MacOS/Brave Browser"  # macOS path—edit for Windows/Linux
opts.add_argument("--no-sandbox")
opts.add_argument("--disable-dev-shm-usage")
opts.add_argument("--disable-blink-features=AutomationControlled")  # Avoid detection
opts.add_experimental_option("excludeSwitches", ["enable-automation"])
opts.add_experimental_option('useAutomationExtension', False)

# Start driver (auto-downloads ChromeDriver—Brave is Chromium-based)
driver = webdriver.Chrome(service=webdriver.chrome.service.Service(ChromeDriverManager().install()), options=opts)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
wait = WebDriverWait(driver, 10)

def login():
    driver.get("https://drivers.uber.com/login")
    # Enter email
    email_input = wait.until(EC.presence_of_element_located((By.NAME, "email")))
    email_input.send_keys(EMAIL)
    driver.find_element(By.CSS_SELECTOR, "button[type='submit']").click()
    time.sleep(2)
    # Enter password
    pwd_input = wait.until(EC.presence_of_element_located((By.NAME, "password")))
    pwd_input.send_keys(PASSWORD)
    driver.find_element(By.CSS_SELECTOR, "button[type='submit']").click()
    time.sleep(5)  # Wait for dashboard
    print("Logged in!")

def scrape_activities():
    driver.get("https://drivers.uber.com/earnings/activities")
    time.sleep(3)
    
    all_trips = []
    page_num = 1
    while True:
        print(f"Scraping page {page_num}...")
        # Wait for trip rows
        rows = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "[data-testid='earnings-activity-row']")))
        
        for row in rows:
            try:
                # Extract basics from row
                trip_id = row.get_attribute("data-trip-id") or row.find_element(By.CSS_SELECTOR, "[data-testid='trip-id']").text
                start_time = row.find_element(By.CSS_SELECTOR, "[data-testid='start-time']").text
                fare_elem = row.find_element(By.CSS_SELECTOR, "[data-testid='fare']").text
                distance_elem = row.find_element(By.CSS_SELECTOR, "[data-testid='distance']").text
                
                # Click to details
                detail_btn = row.find_element(By.CSS_SELECTOR, "button[aria-label*='View details']")
                detail_btn.click()
                time.sleep(2)
                
                # In details: Get coords & polyline via JS (Uber loads map data)
                start_lat = driver.execute_script("return window.initialState?.trip?.startLat || document.querySelector('[data-lat-start]')?.dataset.latStart")
                start_lng = driver.execute_script("return window.initialState?.trip?.startLng || document.querySelector('[data-lng-start]')?.dataset.lngStart")
                end_lat = driver.execute_script("return window.initialState?.trip?.endLat || document.querySelector('[data-lat-end]')?.dataset.latEnd")
                end_lng = driver.execute_script("return window.initialState?.trip?.endLng || document.querySelector('[data-lng-end]')?.dataset.lngEnd")
                
                # Polyline from map (common Uber pattern)
                encoded_poly = driver.execute_script("""
                    return window.google?.maps?.__gjsload__?.uberTrip?.path?.map(p => [p.lat(), p.lng()])?.map(([lat,lng]) => ({lat,lng})) || 
                           document.querySelector('script[type="application/ld+json"]')?.innerText ? JSON.parse(document.querySelector('script[type="application/ld+json"]').innerText).routePolyline;
                """)
                if isinstance(encoded_poly, str):
                    encoded_poly = encoded_poly  # Already string
                else:
                    encoded_poly = polyline.encode(encoded_poly) if encoded_poly else ""
                
                all_trips.append({
                    "trip_id": trip_id,
                    "start_time": start_time,
                    "end_time": datetime.now().isoformat(),  # Placeholder—parse from page if needed
                    "fare": fare_elem,
                    "distance": distance_elem,
                    "start_lat": start_lat,
                    "start_lng": start_lng,
                    "end_lat": end_lat,
                    "end_lng": end_lng,
                    "encoded_polyline": encoded_poly,
                })
                
                # Back to list
                driver.back()
                time.sleep(1)
            except Exception as e:
                print(f"Row error: {e}")
                driver.back()
                time.sleep(1)
        
        # Next page (if exists)
        try:
            next_btn = driver.find_element(By.CSS_SELECTOR, "button[data-testid='next-page']")
            if "disabled" in next_btn.get_attribute("class"):
                break
            next_btn.click()
            time.sleep(3)
            page_num += 1
        except:
            break
    
    return all_trips

# === RUN ===
login()
trips = scrape_activities()
driver.quit()

df = pd.DataFrame(trips)
df["route_points"] = df["encoded_polyline"].apply(lambda x: polyline.decode(x) if x else [])
df.to_csv(OUTPUT, index=False)
print(f"\nSuccess! {len(df)} trips scraped to {OUTPUT}")